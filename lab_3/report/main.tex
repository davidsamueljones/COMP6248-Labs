\documentclass[11pt,a4paper]{article}
\usepackage[top=1.2cm, bottom=1.8cm, left=1.8cm, right=1.8cm]{geometry}

\usepackage{float}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts,amssymb}
\usepackage[makeroom]{cancel}

% Declarations for tikz drawings
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{calc}
\definecolor{lightgreen}{HTML}{90EE90}
\newcommand*{\boxcolor}{lightgreen}
\makeatletter
\renewcommand{\boxed}[1]{\textcolor{\boxcolor}{%
\tikz[baseline={([yshift=-1ex]current bounding box.center)}] \node [rectangle, minimum width=5ex,rounded corners,draw,line width=0.25mm] {\normalcolor\m@th$\displaystyle#1$};}}
 \makeatother

 % Fix for symbol errors in code listings (see https://tex.stackexchange.com/a/343506)
 \usepackage{etoolbox,xpatch}
 \makeatletter
 \AtBeginEnvironment{minted}{\dontdofcolorbox}
 \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
 \xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \makeatother
 % Fix for distance of captions from listings
 \captionsetup[listing]{skip=-10pt}

% \usepackage[style=authoryear, backend=biber]{biblatex}
% \addbibresource{main.bib}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{COMP6248: Lab Exercise 3}
\author{
David Jones (dsj1n15@soton.ac.uk)}
\date{}
\setlength{\intextsep}{1mm}

\definecolor{mintedbackground}{rgb}{0.95,0.95,0.95}
\newmintedfile[pythoncode]{python}{
    bgcolor=mintedbackground,
    style=friendly,
    % fontfamily=fi4,
    fontsize=\small,
    linenos=true,
    numberblanklines=true,
    numbersep=5pt,
    gobble=0,
    frame=leftline,
    framerule=0.4pt,
    framesep=2mm,
    funcnamehighlighting=true,
    tabsize=4,
    obeytabs=false,
    mathescape=false
    samepage=false,
    showspaces=false,
    showtabs =false,
    texcl=false,
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\begin{document}

\maketitle
\textbf{Task:} Optimisation
\vspace{-0.5em}
\section{Exercise 1}
\textbf{Exercise 1.1:} Optimising the Rastrigin function
\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
    \subfloat[Loss Plot]{\input{figures/loss_plot.pgf}}
    \hspace{1.5mm}
    \subfloat[XY Plot]{\input{figures/contour_plot.pgf}}
    \end{tabular}
    \caption{Optimisation of the Rastrigin function (A=1).}
    \label{fig:pca_sg}
\end{figure}
\noindent Stochastic Gradient Descent with Momentum (SGD+M) converged to the smallest local minima and closest to the global minima; therefore it is considered to perform the best. However, it should be noted that all optimisers got stuck at non-global minima.


\section{Exercise 2}
\textbf{Exercise 2.1:} SVM optimisation on Iris Dataset

\noindent Below are the median validation accuracies for classifying the \text{Iris Versicolor} and \text{Iris Virginica} classes of the Iris Dataset across 100 independent trainings.

\begin{equation*}
\text{Acc}_\text{SGD} = 0.96\quad
\text{Acc}_\text{Adam} = 0.92\quad
\text{Acc}_\text{Random} = 0.40
\end{equation*}

\noindent As expected the accuracies do not reach 100\%, this can be attributed to the classes not being linearly separable. Counter-intuitively random classification is less than 50\%; this may be attributed to the different element count of each class in the validation set.



\end{document}

