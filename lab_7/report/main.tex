\documentclass[11pt,a4paper]{article}
\usepackage[top=1.2cm, bottom=1.8cm, left=1.8cm, right=1.8cm]{geometry}

\usepackage{float}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts,amssymb}
\usepackage[makeroom]{cancel}

% Declarations for tikz drawings
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{calc}
\definecolor{lightgreen}{HTML}{90EE90}
\newcommand*{\boxcolor}{lightgreen}
\makeatletter
\renewcommand{\boxed}[1]{\textcolor{\boxcolor}{%
\tikz[baseline={([yshift=-1ex]current bounding box.center)}] \node [rectangle, minimum width=5ex,rounded corners,draw,line width=0.25mm] {\normalcolor\m@th$\displaystyle#1$};}}
 \makeatother

 % Fix for symbol errors in code listings (see https://tex.stackexchange.com/a/343506)
 \usepackage{etoolbox,xpatch}
 \makeatletter
 \AtBeginEnvironment{minted}{\dontdofcolorbox}
 \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
 \xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \makeatother
 % Fix for distance of captions from listings
 \captionsetup[listing]{skip=-10pt}

% \usepackage[style=authoryear, backend=biber]{biblatex}
% \addbibresource{main.bib}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{COMP6248: Lab Exercise 7}
\author{
David Jones (dsj1n15@soton.ac.uk)}
\date{}
\setlength{\intextsep}{1mm}

\definecolor{mintedbackground}{rgb}{0.95,0.95,0.95}
\newmintedfile[pythoncode]{python}{
    bgcolor=mintedbackground,
    style=friendly,
    % fontfamily=fi4,
    fontsize=\small,
    linenos=true,
    numberblanklines=true,
    numbersep=5pt,
    gobble=0,
    frame=leftline,
    framerule=0.4pt,
    framesep=2mm,
    funcnamehighlighting=true,
    tabsize=4,
    obeytabs=false,
    mathescape=false
    samepage=false,
    showspaces=false,
    showtabs =false,
    texcl=false,
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\begin{document}

\maketitle
\textbf{Task:} Transforming Sequences
\vspace{-0.5em}
\section{Exercise 1}

\textbf{Exercise 1.1:} Training a Sequence-to-Sequence Model
\begin{listing}[H]
    \pythoncode{code/forward.py}
    \caption{Encode \texttt{forward} code snippet.}
    \label{lst:encode_snippet}
    \end{listing}

\noindent\textbf{Exercise 1.2:} Decoding Test
\vspace{0.5em}\\
answer the following
\begin{itemize}
    \item \textbf{why is the order of the output reversed}\\Input sentences are read in reverse because it introduces short term dependencies that make the optimisation problem easier. This results in reversed outputs.
    \item \textbf{what is the point of teacher forcing}\\Teacher forcing is where the ground truth is used as an input to the model for $t + 1$, as opposed to the generated value at $t$. This is done to speed up convergence and improve model skill.
\end{itemize}


\noindent\textbf{Exercise 1.3:} Effect of Sequence Length
\vspace{0.5em}\\
Added options in \texttt{decode} for configuring \texttt{span} (the number of spaces before splitting into a chunk), and \texttt{maxlen} (passed to \texttt{Seq2Seq}). If only the \texttt{span} is changed, only the last encoded letter is returned (\texttt{"..-. .-"} [\texttt{fa}] returns \texttt{a}). Increasing \texttt{maxlen} to 3 corrects this, however this adds SOSs (\texttt{\^}) for shorter inputs. Therefore \texttt{maxlen} should be 1 + \texttt{span} and the input should be divisible by \texttt{span}.\\

\noindent Setting \texttt{maxlen} and \texttt{span} appropriately such that the full string can be decoded as a single chunk: inputting the first item from the dataset (\texttt{".--. .-. . ..-. .-"} [\texttt{prefa}]) will decode successfully. Appending an extra character \texttt{".-"} [\texttt{a}] causes an unsuccessful decode (\texttt{rpaswa}). Notably, it is not just the length of string that allows \texttt{prefa} to decode, an input of the same length not present in the dataset (\texttt{aaaaa}) will fail (returns \texttt{raaaa}). This indicates the LSTM has learnt the dataset.

\end{document}

