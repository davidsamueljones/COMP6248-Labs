{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"7_1_SequenceModelling.ipynb","provenance":[{"file_id":"https://github.com/ecs-vlc/COMP6248/blob/master/docs/labs/lab7/7_1_SequenceModelling.ipynb","timestamp":1589420863378}],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4ec72283cc82478f9bc35550d75986b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_33854cdf81e54c86bb05ebd21b4ff16d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4353f0d617b2415cafe222be91d4e8fb","IPY_MODEL_35feecca54554cc68087fc5160be27c9"]}},"33854cdf81e54c86bb05ebd21b4ff16d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4353f0d617b2415cafe222be91d4e8fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58d90687475f49de981b73021a29c328","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab7495e38229441da269f5c7af1c971b"}},"35feecca54554cc68087fc5160be27c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb88bdce3c8c43d7b0de91cc7e0770c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 606208/? [00:20&lt;00:00, 314297.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef657ff8cffe498c9db85210b2e310ff"}},"58d90687475f49de981b73021a29c328":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab7495e38229441da269f5c7af1c971b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb88bdce3c8c43d7b0de91cc7e0770c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef657ff8cffe498c9db85210b2e310ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7561cdcc98543a5b573022eb97401cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f43b042e796f4d6584d258b1517b184d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8dabebeee8fd4c3ebc2f2f31afa9234b","IPY_MODEL_834a6a293cb34041abb87db8383e3cdf"]}},"f43b042e796f4d6584d258b1517b184d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dabebeee8fd4c3ebc2f2f31afa9234b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe84c99ddcbb49b1ba6215c97eb15e28","_dom_classes":[],"description":"0/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_617f5ece31e349ef8e50a85cf79a8af9"}},"834a6a293cb34041abb87db8383e3cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_899cc2c35cff44368d177e9e66c71514","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:53&lt;00:00, 29.26it/s, acc=0.3761, loss=2.1407, running_acc=0.4816, running_loss=1.7409]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd51d3e7bbc6470d9dc6a4cc2b51b20a"}},"fe84c99ddcbb49b1ba6215c97eb15e28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"617f5ece31e349ef8e50a85cf79a8af9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"899cc2c35cff44368d177e9e66c71514":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd51d3e7bbc6470d9dc6a4cc2b51b20a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7459eb98c31400f94b09d54b91dd25b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d7879035ea964272997ad3206d2aae3f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3f8c1a24efc9411cba97f45d3ee52bd3","IPY_MODEL_2c1c3b48b34c41c8955325773f4ddd60"]}},"d7879035ea964272997ad3206d2aae3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f8c1a24efc9411cba97f45d3ee52bd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e8442c35ae7345fcb09d0dff6ca3f624","_dom_classes":[],"description":"1/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0562b4b79f81407b812baefce500e28f"}},"2c1c3b48b34c41c8955325773f4ddd60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b5eb136d6114730998d40b3857f6e50","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:57&lt;00:00, 27.25it/s, acc=0.4969, loss=1.6898, running_acc=0.5263, running_loss=1.5636]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e661b2876c474576931398121d6b3a6c"}},"e8442c35ae7345fcb09d0dff6ca3f624":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0562b4b79f81407b812baefce500e28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b5eb136d6114730998d40b3857f6e50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e661b2876c474576931398121d6b3a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4159285263ff4a75bd182da315e2bbd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_49bc9404e1034b509c5ed22fd7ec3b8c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7d64713b131478da90902425b4d5e9c","IPY_MODEL_ba838e6ff96f48a18ee5754d0d329603"]}},"49bc9404e1034b509c5ed22fd7ec3b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7d64713b131478da90902425b4d5e9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_18947bc0ade047dab81a8cd440f9fa63","_dom_classes":[],"description":"2/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1aa11e1615ad4e58942f65eb7c01e19f"}},"ba838e6ff96f48a18ee5754d0d329603":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bdb6e4b396e426395dd02c3b66997bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:53&lt;00:00, 29.24it/s, acc=0.5247, loss=1.5854, running_acc=0.5444, running_loss=1.4975]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0850be9c8154ab69d6cee9889d8965a"}},"18947bc0ade047dab81a8cd440f9fa63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1aa11e1615ad4e58942f65eb7c01e19f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bdb6e4b396e426395dd02c3b66997bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d0850be9c8154ab69d6cee9889d8965a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ae9db7b9ee648e5afb95ea81375ca2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_08da0c3404ef413381d26a570500b5d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1a6e72b4d62b43e8a242ece5c6ddcf7b","IPY_MODEL_f29d9565605142d7a3ba28069d342c95"]}},"08da0c3404ef413381d26a570500b5d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a6e72b4d62b43e8a242ece5c6ddcf7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b07ae2aa7db744948a1349312368097f","_dom_classes":[],"description":"3/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_78be429ea35b493fa34cf8d908425d26"}},"f29d9565605142d7a3ba28069d342c95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3dd097b4ac2142ff85100ba58c3bc68a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.55it/s, acc=0.5372, loss=1.5382, running_acc=0.5512, running_loss=1.4643]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0585191b52c6468fa2b19014ab183605"}},"b07ae2aa7db744948a1349312368097f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"78be429ea35b493fa34cf8d908425d26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dd097b4ac2142ff85100ba58c3bc68a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0585191b52c6468fa2b19014ab183605":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c677737da154d6c9b242e97f360ef4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4fb616cdbb8446d7acafe9fe74692b00","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_929fb3a6e8c54064b7db972d1f1dbd62","IPY_MODEL_7de7ba1d80c043e5a7e254d5a81a3afd"]}},"4fb616cdbb8446d7acafe9fe74692b00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"929fb3a6e8c54064b7db972d1f1dbd62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4511625321dc4d3590856f623ccca09f","_dom_classes":[],"description":"4/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74320909b35e44849ad030e2a277e784"}},"7de7ba1d80c043e5a7e254d5a81a3afd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_126b6d78a1bf44c58e59be530d82bd95","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.56it/s, acc=0.5432, loss=1.5135, running_acc=0.5528, running_loss=1.451]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc034ae8753d4082909ee741bc2891d3"}},"4511625321dc4d3590856f623ccca09f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74320909b35e44849ad030e2a277e784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"126b6d78a1bf44c58e59be530d82bd95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cc034ae8753d4082909ee741bc2891d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8aa29c81cd64790b8a4d72addd4ad45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_90114e6d36ea48d6a24e47014d6123f5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a1debb2b80814e098b2e2fb137091454","IPY_MODEL_99ffb4e365ea4fb1b543b5d3882fb83e"]}},"90114e6d36ea48d6a24e47014d6123f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1debb2b80814e098b2e2fb137091454":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7aa0bdcec22b47a4896162cfbe28faf3","_dom_classes":[],"description":"5/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bf080047b0a429f92c2dcb1235c28ac"}},"99ffb4e365ea4fb1b543b5d3882fb83e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cff8a44b3b6348d699f25b25819b534f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.58it/s, acc=0.5468, loss=1.4993, running_acc=0.5562, running_loss=1.429]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd1a50d4cc794c6cb7181dfff17ff75c"}},"7aa0bdcec22b47a4896162cfbe28faf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bf080047b0a429f92c2dcb1235c28ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cff8a44b3b6348d699f25b25819b534f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd1a50d4cc794c6cb7181dfff17ff75c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cc049f2d8d64bb197348ac61f08fce9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8eb8f7d48588473b933faa8bc549dd5f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_be1140e69c5a47df93a73d81f9a9bbc0","IPY_MODEL_f9241373c9b44233bcf900dc9fb3e1c3"]}},"8eb8f7d48588473b933faa8bc549dd5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be1140e69c5a47df93a73d81f9a9bbc0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7813c8bd63214889beef7d3fbc77ae98","_dom_classes":[],"description":"6/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d2d8438b16f4015a90109e21bddf2c4"}},"f9241373c9b44233bcf900dc9fb3e1c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6f68bb226f5b4082b89a04d5ca2dc33f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.82it/s, acc=0.5507, loss=1.4856, running_acc=0.5594, running_loss=1.42]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ef11087c67d4222a9b76faf1a617abb"}},"7813c8bd63214889beef7d3fbc77ae98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d2d8438b16f4015a90109e21bddf2c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f68bb226f5b4082b89a04d5ca2dc33f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ef11087c67d4222a9b76faf1a617abb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f46fe56f1c3949628c0cdc103c529996":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d88d014a26e444069832aa5fab3cf951","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_873a1cba914f4df798e613eb1a0d42a0","IPY_MODEL_3431f85b7b9746daaff0246b7f6b1c9e"]}},"d88d014a26e444069832aa5fab3cf951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"873a1cba914f4df798e613eb1a0d42a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_506825c9bd47473ba6e5f88e49aea061","_dom_classes":[],"description":"7/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ab4db346ab24085abf64308a6308bc4"}},"3431f85b7b9746daaff0246b7f6b1c9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c5f776509d014b108a4042f7824c8a27","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.63it/s, acc=0.5529, loss=1.4767, running_acc=0.5628, running_loss=1.4108]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de6ec676755e4d4eaf91000421d79c5c"}},"506825c9bd47473ba6e5f88e49aea061":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9ab4db346ab24085abf64308a6308bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5f776509d014b108a4042f7824c8a27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de6ec676755e4d4eaf91000421d79c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17b1944d7e3841a885419d49a628f07c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d6225be6b52425e8c17c9d8546d59c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9e28e89a8f841fbbad4a60699624a21","IPY_MODEL_ee92613d65134a4e85a01571799d3432"]}},"1d6225be6b52425e8c17c9d8546d59c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9e28e89a8f841fbbad4a60699624a21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79f4e3afc18b45ed86260c58fea37716","_dom_classes":[],"description":"8/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8cb85d628724c66a489b29ef7e4aed4"}},"ee92613d65134a4e85a01571799d3432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c26a3d9d1827492d944cd3a613f5c827","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:53&lt;00:00, 29.20it/s, acc=0.5544, loss=1.4731, running_acc=0.5664, running_loss=1.4074]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51d7a8ca1be14b9a92ef73555b19f931"}},"79f4e3afc18b45ed86260c58fea37716":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f8cb85d628724c66a489b29ef7e4aed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c26a3d9d1827492d944cd3a613f5c827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51d7a8ca1be14b9a92ef73555b19f931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47cbb739c976408caf171e0984cd9904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f22299554f324e7ea4beca50ef58d9d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4206ab280d50402ab04fb06cd3d98bd9","IPY_MODEL_e4b750eb7bb047d3b0dca24fe54ab9f1"]}},"f22299554f324e7ea4beca50ef58d9d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4206ab280d50402ab04fb06cd3d98bd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6abcf94d722b4e90b5745cc95a5b6a32","_dom_classes":[],"description":"9/10(t): 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4d1901cb2d74a49a7feb95a25d3bc2c"}},"e4b750eb7bb047d3b0dca24fe54ab9f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5ca51b0e919c4e62bf64cbaba521dbbf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1565/1565 [00:52&lt;00:00, 29.60it/s, acc=0.5557, loss=1.4671, running_acc=0.5686, running_loss=1.3999]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5749ede710a4a838ae9661882e7a3bc"}},"6abcf94d722b4e90b5745cc95a5b6a32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f4d1901cb2d74a49a7feb95a25d3bc2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ca51b0e919c4e62bf64cbaba521dbbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e5749ede710a4a838ae9661882e7a3bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"40fe1c0748661d409405f09e9250edcf","grade":false,"grade_id":"cell-f67b416b0411edc1","locked":true,"schema_version":1,"solution":false},"id":"00-xz7Kn3YQ8","colab_type":"text"},"source":["# Part 1: Sequence Modelling"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"ed5be3ed6978c8f54e5301bbb9d0d0bd","grade":false,"grade_id":"cell-a328195514e4147d","locked":true,"schema_version":1,"solution":false},"id":"XQpEDhM13YQ9","colab_type":"text"},"source":["__Before starting, we recommend you enable GPU acceleration if you're running on Colab.__"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5d3c83086d3c94835d3f8510df7f8d0f","grade":false,"grade_id":"cell-52dc2d0ecf866f90","locked":true,"schema_version":1,"solution":false},"id":"yEi0HXZj3YQ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"1f215bf1-6cbf-43c8-c1a0-f0712f6346af","executionInfo":{"status":"ok","timestamp":1589556071290,"user_tz":-60,"elapsed":8366,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["# Execute this code block to install dependencies when running on colab\n","try:\n","    import torch\n","except:\n","    from os.path import exists\n","    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n","\n","try: \n","    import torchbearer\n","except:\n","    !pip install torchbearer\n","import torchbearer"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting torchbearer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e9/4049a47dd2e5b6346a2c5d215b0c67dce814afbab1cd54ce024533c4834e/torchbearer-0.5.3-py3-none-any.whl (138kB)\n","\r\u001b[K     |██▍                             | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.5.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.18.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbearer) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->torchbearer) (0.16.0)\n","Installing collected packages: torchbearer\n","Successfully installed torchbearer-0.5.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"e9c1849d2839e6c1ebac8b563fe9d0bc","grade":false,"grade_id":"cell-36906cd59153af5b","locked":true,"schema_version":1,"solution":false},"id":"5Ug_dr-v3YRA","colab_type":"text"},"source":["## Markov chains\n","\n","We'll start our exploration of modelling sequences and building generative models using a 1st order Markov chain. The Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. In our case we're going to learn a model over a set of characters from an English language text. The events, or states, in our model are the set of possible characters, and we'll learn the probability of moving from one character to the next.\n","\n","Let's start by loading the data from the web:"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"508d37e774c4619f7c4706291f52c466","grade":false,"grade_id":"cell-a592d788c1587e58","locked":true,"schema_version":1,"solution":false},"id":"S2uBoEYv3YRB","colab_type":"code","outputId":"e65a8f15-c2de-4131-8ac1-d8279b0fdb2c","executionInfo":{"status":"ok","timestamp":1589556077562,"user_tz":-60,"elapsed":1960,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}},"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["4ec72283cc82478f9bc35550d75986b5","33854cdf81e54c86bb05ebd21b4ff16d","4353f0d617b2415cafe222be91d4e8fb","35feecca54554cc68087fc5160be27c9","58d90687475f49de981b73021a29c328","ab7495e38229441da269f5c7af1c971b","cb88bdce3c8c43d7b0de91cc7e0770c3","ef657ff8cffe498c9db85210b2e310ff"]}},"source":["from torchvision.datasets.utils import download_url\n","import torch\n","import random\n","import sys\n","import io\n","\n","# Read the data\n","download_url('https://s3.amazonaws.com/text-datasets/nietzsche.txt', '.', 'nietzsche.txt', None)\n","text = io.open('./nietzsche.txt', encoding='utf-8').read().lower()\n","print('corpus length:', len(text))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://s3.amazonaws.com/text-datasets/nietzsche.txt to ./nietzsche.txt\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ec72283cc82478f9bc35550d75986b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["corpus length: 600893\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"a1b08d3393744a64f2d1991d8ddd3c1a","grade":false,"grade_id":"cell-f345306b2d88866e","locked":true,"schema_version":1,"solution":false},"id":"wAx0JdlV3YRD","colab_type":"text"},"source":["We now need to iterate over the characters in the text and count the times each transition happens:"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"8452011964d66c1c591df5d4f49c82b6","grade":false,"grade_id":"cell-21c1c86b5d26778f","locked":true,"schema_version":1,"solution":false},"id":"e96MzkRo3YRD","colab_type":"code","colab":{}},"source":["transition_counts = dict()\n","for i in range(0,len(text)-1):\n","    currc = text[i]\n","    nextc = text[i+1]\n","    if currc not in transition_counts:\n","        transition_counts[currc] = dict()\n","    if nextc not in transition_counts[currc]:\n","        transition_counts[currc][nextc] = 0\n","    transition_counts[currc][nextc] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"73f178f03f644719a7684c942212b488","grade":false,"grade_id":"cell-f93390ea74e0de36","locked":true,"schema_version":1,"solution":false},"id":"7G1WvY1x3YRG","colab_type":"text"},"source":["The `transition_counts` dictionary maps the current character to the next character, and this is then mapped to a count. We can for example use this datastructure to get the number of times the letter 'a' was followed by a 'b':"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"d37afa35d97a35848444cbffb3d4369c","grade":false,"grade_id":"cell-ed4eee0105f3a0cf","locked":true,"schema_version":1,"solution":false},"id":"f1nb-wg93YRH","colab_type":"code","outputId":"07064f4a-b1ee-4e8d-9dfb-0c6dbe6cf1d0","executionInfo":{"status":"ok","timestamp":1589549374103,"user_tz":-60,"elapsed":12068,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Number of transitions from 'a' to 'b': \" + str(transition_counts['a']['b']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of transitions from 'a' to 'b': 813\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"89b218435d0475de2fd126d6cf654d07","grade":false,"grade_id":"cell-195d5f1aebd40797","locked":true,"schema_version":1,"solution":false},"id":"xGnLVlVP3YRJ","colab_type":"text"},"source":["Finally, to complete the model we need to normalise the counts for each initial character into a probability distribution over the possible next character. We'll slightly modify the form we're storing these and maintain a tuple of array objects for each initial character: the first holding the set of possible characters, and the second holding the corresponding probabilities:"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"9dbad32065a0c97c65cc5760b5efa718","grade":false,"grade_id":"cell-28d68d95d39e3180","locked":true,"schema_version":1,"solution":false},"id":"YWzRKBil3YRJ","colab_type":"code","colab":{}},"source":["transition_probabilities = dict()\n","for currentc, next_counts in transition_counts.items():\n","    values = []\n","    probabilities = []\n","    sumall = 0\n","    for nextc, count in next_counts.items():\n","        values.append(nextc)\n","        probabilities.append(count)\n","        sumall += count\n","    for i in range(0, len(probabilities)):\n","        probabilities[i] /= float(sumall)\n","    transition_probabilities[currentc] = (values, probabilities)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"7e7336b1ef946f10dc63020be2b17ecf","grade":false,"grade_id":"cell-f79188db65a705aa","locked":true,"schema_version":1,"solution":false},"id":"D9hcm_iW3YRL","colab_type":"text"},"source":["At this point, we could print out the probability distribution for a given initial character state. For example, to print the distribution for 'a':"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5eaaf96ae4181ad3a2b7087d9643ff1f","grade":false,"grade_id":"cell-ee624b4c0ff2c64f","locked":true,"schema_version":1,"solution":false},"id":"Xq_bMExX3YRM","colab_type":"code","outputId":"ae42c844-f720-42d5-cc8e-1e78e2a023ce","executionInfo":{"status":"ok","timestamp":1589556111331,"user_tz":-60,"elapsed":1057,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["for a,b in zip(transition_probabilities['a'][0], transition_probabilities['a'][1]):\n","    print(a,b)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["c 0.03685183172083922\n","t 0.14721708881400153\n","  0.05296771388194369\n","n 0.2322806826829003\n","l 0.11552886183280792\n","r 0.08794434177628004\n","s 0.0968583541689314\n","v 0.0192412218719426\n","i 0.03402543754755952\n","d 0.026986628981411024\n","g 0.017202956843135123\n","y 0.02505707142080661\n","k 0.012827481247961734\n","b 0.02209479291227307\n","p 0.020545711490379388\n","m 0.02030111968692249\n","u 0.011414284161321883\n","f 0.004429829329274921\n","w 0.004837482335036417\n",", 0.0010870746820306554\n","\n"," 0.005353842809000978\n","z 0.0006522448092183933\n","x 0.0007609522774214588\n","o 0.0005435373410153277\n",". 0.000489183606913795\n","- 0.0004348298728122622\n","' 5.4353734101532776e-05\n","j 0.0004348298728122622\n","h 0.00035329927165996303\n","e 0.0007337754103706925\n",": 5.4353734101532776e-05\n","a 5.4353734101532776e-05\n",") 0.00010870746820306555\n","! 2.7176867050766388e-05\n","; 2.7176867050766388e-05\n","\" 8.153060115229916e-05\n","q 2.7176867050766388e-05\n","_ 8.153060115229916e-05\n","[ 2.7176867050766388e-05\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"93b3745091fcb17322253b02af1bc2d9","grade":false,"grade_id":"cell-9cc2f51ebb3ea728","locked":true,"schema_version":1,"solution":false},"id":"F0jP6GKP3YRO","colab_type":"text"},"source":["It looks like the most probable letter to follow an 'a' is 'n'. \n","\n","__What is the most likely letter to follow the letter 'j'? Write your answer in the block below:__"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"bd3cad04582e881ebc595619cef14fd1","grade":true,"grade_id":"cell-2a3a71268b5a2df9","locked":false,"points":1,"schema_version":1,"solution":true},"id":"2NLB594s3YRO","colab_type":"code","outputId":"014577aa-8132-4f58-9af5-03e42490dc9c","executionInfo":{"status":"ok","timestamp":1589556191983,"user_tz":-60,"elapsed":968,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["c = 'j'\n","zipped = zip(transition_probabilities[c][0], transition_probabilities[c][1])\n","print(max(zipped, key=lambda x: x[1]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["('u', 0.5709156193895871)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"fb10d0a7366b0f59055017a39614e93e","grade":false,"grade_id":"cell-43b70458c31baaf3","locked":true,"schema_version":1,"solution":false},"id":"EX18B2aH3YRQ","colab_type":"text"},"source":["We mentioned earlier that the Markov model is generative. This means that we can draw samples from the distributions and iteratively move between states. \n","\n","Use the following code block to iteratively sample 1000 characters from the model, starting with an initial character 't'. You can use the `torch.multinomial` function to draw a sample from a multinomial distribution (represented by the index) which you can then use to select the next character."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"4f50c283225208b2043431a1c2da104f","grade":true,"grade_id":"cell-5be0d1f3fc6e8f65","locked":false,"points":4,"schema_version":1,"solution":true},"id":"C12ny_IY3YRR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"b00156d0-7b3e-47be-9370-9312906a7b04","executionInfo":{"status":"ok","timestamp":1589556842698,"user_tz":-60,"elapsed":1041,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["current = 't'\n","for i in range(0, 1000):\n","    print(current, end='')\n","    # sample the next character based on `current` and store the result in `current`\n","    next_probs = transition_probabilities[current][1]\n","    index = torch.multinomial(torch.tensor(next_probs), 1)\n","    current = transition_probabilities[current][0][index]\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["th rns r th f callespreigtaly stitht ttouthaly t ue ala tuegs\n","veeler atintonso, fiche r witheins ts inevel acerofik d\n","on ompoyty iio ntos\n","9]-----isene ni ts, and aces. me  o he\n","ceane. panthe wif ighilus wn, w, faca himas:-g\n","435. ibe tioorech ay besidrinsfty tsigutriere ior wse niny d whe acur tealouphr s itoniored nsin foideresurodoprtaio ardsin athe, t, f w hur idang--the iofilorth s panelonve naseny anect-thy end thevispesif\n","f tercanguthilit.\n","tiruris heaud orowomiris ctinthas offfofiand, toslf lo toprad ichenge. s wal h tind n wnchidems the ald wh figingoss seitinto \"g se inc, co es s vizerdatr\n","[1057.\n","tist ss taste'sefry t isy\n","pe f sofutr oore o\n","weaghomucugisarcelyrsasthaknecetonde res ive tonghy the varere, arofof d at inghe thertrndig) be in e\n","in ive thandentiot amer ow comed _nchirand ticreaf cescerilason, ince athesedinooreysucooms amue se cower: torst plas, \" end ed bes, heprin) ans g, d\n","ent wematiche wntuf e an, by, atsced way ha, sth d, d\n","iger cye osur ton inyis\n","hisy she anato"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"56c49154c48797d312762e4761085bf7","grade":false,"grade_id":"cell-de87ac1c9708205f","locked":true,"schema_version":1,"solution":false},"id":"OwpakvBE3YRS","colab_type":"text"},"source":["You should observe a result that is clearly not English, but it should be obvious that some of the common structures in the English language have been captured.\n","\n","__Rather than building a model based on individual characters, can you implement a model in the following code block that works on words instead?__"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"ed71d61ce7a2f648d7507693902da3d7","grade":true,"grade_id":"cell-a6d4a8a639190296","locked":false,"points":5,"schema_version":1,"solution":true},"id":"p-e3p4Yg3YRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"43d51c09-a188-43d5-a580-d579938c36f0","executionInfo":{"status":"ok","timestamp":1589558549567,"user_tz":-60,"elapsed":1097,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["import re\n","\n","# Split off constructs\n","construct_re = r\"([\\.,!\\n])\"\n","replaced = re.sub(construct_re, r\" \\1\", text)\n","assert replaced != text\n","words = replaced.split()\n","\n","transition_counts = dict()\n","for i in range(0,len(words)-1):\n","    currw = words[i]\n","    nextw = words[i+1]\n","    if currw not in transition_counts:\n","        transition_counts[currw] = dict()\n","    if nextw not in transition_counts[currw]:\n","        transition_counts[currw][nextw] = 0\n","    transition_counts[currw][nextw] += 1\n","\n","transition_probabilities = dict()\n","for currentw, next_counts in transition_counts.items():\n","    values = []\n","    probabilities = []\n","    sumall = 0\n","    for nextw, count in next_counts.items():\n","        values.append(nextw)\n","        probabilities.append(count)\n","        sumall += count\n","    for i in range(0, len(probabilities)):\n","        probabilities[i] /= float(sumall)\n","    transition_probabilities[currentw] = (values, probabilities)\n","\n","current = \"according\"\n","for i in range(0, 100):\n","    print(current, end=\"\")\n","    # sample the next character based on `current` and store the result in `current`\n","    next_probs = transition_probabilities[current][1]\n","    index = torch.multinomial(torch.tensor(next_probs), 1)\n","    current = transition_probabilities[current][0][index]\n","    end = \"\" if re.match(construct_re, current) else \" \"\n","    print(end, end=\"\")\n","\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["according to everything in the elimination of sexual gratification, the way, as in general depression at last just the eye which, for truth? from me.\" why it was corruption:--it was a couple of \"nothing suiting\" us the good consciences: we all these motives if they are enclosed by the true to themselves by the history of the distinctive characteristic of heart--and the end solemnly christened \"the rules and concludes by him incredible. it is effect, and there are so because men as he acknowledges under their thorough and subtlety, a deeper cave: an "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"cd494f7c9fd0e838e74a5c70cd5ef773","grade":false,"grade_id":"cell-d54dcdc1d540df4f","locked":true,"schema_version":1,"solution":false},"id":"o5tIAew63YRV","colab_type":"text"},"source":["## RNN-based sequence modelling\n","\n","It is possible to build higher-order Markov models that capture longer-term dependencies in the text and have higher accuracy, however this does tend to become computationally infeasible very quickly. Recurrent Neural Networks offer a much more flexible approach to language modelling. \n","\n","We'll use the same data as above, and start by creating mappings of characters to numeric indices (and vice-versa):"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"ae5b316a7c13ecd23143d4dfa35bee5c","grade":false,"grade_id":"cell-d152a2cb9707a4c4","locked":true,"schema_version":1,"solution":false},"id":"7nOzuS883YRV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"6cad67ab-01e6-4d76-c4a0-454b364bea22","executionInfo":{"status":"ok","timestamp":1589558229070,"user_tz":-60,"elapsed":1272,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["total chars: 57\n","{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: '=', 23: '?', 24: '[', 25: ']', 26: '_', 27: 'a', 28: 'b', 29: 'c', 30: 'd', 31: 'e', 32: 'f', 33: 'g', 34: 'h', 35: 'i', 36: 'j', 37: 'k', 38: 'l', 39: 'm', 40: 'n', 41: 'o', 42: 'p', 43: 'q', 44: 'r', 45: 's', 46: 't', 47: 'u', 48: 'v', 49: 'w', 50: 'x', 51: 'y', 52: 'z', 53: 'ä', 54: 'æ', 55: 'é', 56: 'ë'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f5f0f03e31eccfb78d1756139f90e1ac","grade":false,"grade_id":"cell-46a85547d03a1f30","locked":true,"schema_version":1,"solution":false},"id":"3t1eWQUB3YRZ","colab_type":"text"},"source":["We'll also write some helper functions to encode and decode the data to/from tensors of indices, and an implementation of a `torch.Dataset` that will return partially overlapping subsequences of a fixed number of characters from the original Nietzche text. Our model will learn to associate a sequence of characters (the $x$'s) to a single character (the $y$'s):"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"fb93c4daba5adbfabf8ef5656cc89543","grade":false,"grade_id":"cell-64f8b2518a008c54","locked":true,"schema_version":1,"solution":false},"id":"_rB7TipN3YRZ","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","from torch.nn import functional as F\n","from torch import optim\n","import random\n","import sys\n","import io\n","\n","maxlen = 40\n","step = 3\n","\n","\n","def encode(inp):\n","    # encode the characters in a tensor\n","    x = torch.zeros(maxlen, dtype=torch.long)\n","    for t, char in enumerate(inp):\n","        x[t] = char_indices[char]\n","\n","    return x\n","\n","\n","def decode(ten):\n","    s = ''\n","    for v in ten:\n","        s += indices_char[v] \n","    return s\n","\n","\n","class MyDataset(Dataset):\n","    # cut the text in semi-redundant sequences of maxlen characters\n","    def __len__(self):\n","        return (len(text) - maxlen) // step\n","\n","    def __getitem__(self, i):\n","        inp = text[i*step: i*step + maxlen]\n","        out = text[i*step + maxlen]\n","\n","        x = encode(inp)\n","        y = char_indices[out]\n","\n","        return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"df5113fc9d6d635dca32463f07fcb7d1","grade":false,"grade_id":"cell-bdbb9997aa91863b","locked":true,"schema_version":1,"solution":false},"id":"UgHMcAtg3YRb","colab_type":"text"},"source":["We can now define the model. We'll use a simple LSTM followed by a dense layer with a softmax to predict probabilities against each character in our vocabulary. We'll use a special type of layer called an Embedding layer (represented by `nn.Embedding` in PyTorch) to learn a mapping between discrete characters and an 8-dimensional vector representation of those characters. You'll learn more about Embeddings in the next part of the lab."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"2d79273b7a17d28c4d6c93e3d22927f5","grade":false,"grade_id":"cell-2aa5e9483ccd6ba4","locked":true,"schema_version":1,"solution":false},"id":"M_UgbkqJ3YRb","colab_type":"code","colab":{}},"source":["class CharPredictor(nn.Module):\n","    def __init__(self):\n","        super(CharPredictor, self).__init__()\n","        self.emb = nn.Embedding(len(chars), 8)\n","        self.lstm = nn.LSTM(8, 128, batch_first=True)\n","        self.lin = nn.Linear(128, len(chars))\n","\n","    def forward(self, x):\n","        x = self.emb(x)\n","        lstm_out, _ = self.lstm(x)\n","        out = self.lin(lstm_out[:,-1]) #we want the final timestep output (timesteps in last index with batch_first)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"8d9e5e92460bbe5a977021f631362478","grade":false,"grade_id":"cell-eda65e7ef08f66a5","locked":true,"schema_version":1,"solution":false},"id":"ao2woTXF3YRe","colab_type":"text"},"source":["We could train our model at this point, but it would be nice to be able to sample it during training so we can see how its learning. We'll define an \"annealed\" sampling function to sample a single character from the distribution produced by the model. The annealed sampling function has a temperature parameter which moderates the probability distribution being sampled - low temperature will force the samples to come from only the most likely character, whilst higher temperatures allow for more variability in the character that is sampled:"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5aedd2ccd26ef2d6505278a7894671e4","grade":false,"grade_id":"cell-be521ae6b656234a","locked":true,"schema_version":1,"solution":false},"id":"OJl3CxE13YRe","colab_type":"code","colab":{}},"source":["def sample(logits, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    logits = logits / temperature\n","    return torch.multinomial(F.softmax(logits, dim=0), 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5057964b1e77f5ba8c92abf3148ce73f","grade":false,"grade_id":"cell-981d79ec1593b83b","locked":true,"schema_version":1,"solution":false},"id":"OEOU_BwU3YRh","colab_type":"text"},"source":["Torchbearer lets us define callbacks which can be triggered during training (for example at the end of each epoch). Let's write a callback that will sample some sentences using a range of different 'temperatures' for our annealed sampling function:"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"44f0bad7cc7aa788fa4111d6a55766ca","grade":false,"grade_id":"cell-788b63e92e811aa8","locked":true,"schema_version":1,"solution":false},"id":"9AOPHq553YRi","colab_type":"code","colab":{}},"source":["import torchbearer\n","from torchbearer import Trial\n","from torchbearer.callbacks.decorators import on_end_epoch\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","@on_end_epoch\n","def create_samples(state):\n","    with torch.no_grad():\n","        epoch = -1\n","        if state is not None:\n","            epoch = state[torchbearer.EPOCH]\n","\n","        print()\n","        print('----- Generating text after Epoch: %d' % epoch)\n","\n","        start_index = random.randint(0, len(text) - maxlen - 1)\n","        for diversity in [0.2, 0.5, 1.0, 1.2]:\n","            print()\n","            print()\n","            print('----- diversity:', diversity)\n","\n","            generated = ''\n","            sentence = text[start_index:start_index+maxlen-1]\n","            generated += sentence\n","            print('----- Generating with seed: \"' + sentence + '\"')\n","            print()\n","            sys.stdout.write(generated)\n","\n","            inputs = encode(sentence).unsqueeze(0).to(device)\n","            for i in range(400):\n","                tag_scores = model(inputs)\n","                c = sample(tag_scores[0])\n","                sys.stdout.write(indices_char[c.item()])\n","                sys.stdout.flush()\n","                inputs[0, 0:inputs.shape[1]-1] = inputs[0, 1:].clone()\n","                inputs[0, inputs.shape[1]-1] = c\n","        print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"1da7de78addd5726d2a156d5dc983e9c","grade":false,"grade_id":"cell-2dc6814904f12692","locked":true,"schema_version":1,"solution":false},"id":"MAvb1RPR3YRk","colab_type":"text"},"source":["Now, all the pieces are in place. __Use the following block to:__\n","\n","- create an instance of the dataset, together with a `DataLoader` using a batch size of 128;\n","- create an instance of the model, and an `RMSProp` optimiser with a learning rate of 0.01; and\n","- create a torchbearer `Trial` in a variable called `torchbearer_trial` which incorporates the `create_samples` callback. Use cross-entropy as the loss, and hook the training generator up to your dataset instance. Make sure you move your `Trial` object to the GPU if one is available."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"d31a6ee7d253ba186dc92bebe139ece3","grade":true,"grade_id":"cell-9c17e699a59cd71c","locked":false,"points":10,"schema_version":1,"solution":true},"id":"_knzeW2u3YRk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"22d8f5d4-b19a-41ca-ae41-9811491db934","executionInfo":{"status":"ok","timestamp":1589559972947,"user_tz":-60,"elapsed":1797,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","dataset = MyDataset()\n","trainloader = DataLoader(dataset, batch_size=128)\n","model = CharPredictor()\n","optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torchbearer_trial = Trial(model, optimizer, criterion, metrics=['acc', 'loss'], callbacks = [create_samples]).to(device)\n","torchbearer_trial.with_generators(train_generator=trainloader)"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["--------------------- OPTIMZER ---------------------\n","RMSprop (\n","Parameter Group 0\n","    alpha: 0.99\n","    centered: False\n","    eps: 1e-08\n","    lr: 0.01\n","    momentum: 0\n","    weight_decay: 0\n",")\n","\n","-------------------- CRITERION ---------------------\n","CrossEntropyLoss()\n","\n","--------------------- METRICS ----------------------\n","['acc', 'loss']\n","\n","-------------------- CALLBACKS ---------------------\n","['torchbearer.callbacks.decorators.LambdaCallback']\n","\n","---------------------- MODEL -----------------------\n","CharPredictor(\n","  (emb): Embedding(57, 8)\n","  (lstm): LSTM(8, 128, batch_first=True)\n","  (lin): Linear(in_features=128, out_features=57, bias=True)\n",")\n"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"bdf13f8a87d1ef999f3c1ee8e083d7fe","grade":false,"grade_id":"cell-f70caee6c691fd1d","locked":true,"schema_version":1,"solution":false},"id":"SHkOXek-3YRo","colab_type":"text"},"source":["Finally, run the following block to train the model and print out generated samples after each epoch. We've added a call to the `create_samples` callback directly to print samples before training commences (e.g. with random weights). Be aware this will take some time to run..."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"2b52b125ce1a870bc1cc96b8dc130bc9","grade":false,"grade_id":"cell-ab250fe0c0be1234","locked":true,"schema_version":1,"solution":false},"id":"aW6R1rbD3YRp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a7561cdcc98543a5b573022eb97401cf","f43b042e796f4d6584d258b1517b184d","8dabebeee8fd4c3ebc2f2f31afa9234b","834a6a293cb34041abb87db8383e3cdf","fe84c99ddcbb49b1ba6215c97eb15e28","617f5ece31e349ef8e50a85cf79a8af9","899cc2c35cff44368d177e9e66c71514","bd51d3e7bbc6470d9dc6a4cc2b51b20a","a7459eb98c31400f94b09d54b91dd25b","d7879035ea964272997ad3206d2aae3f","3f8c1a24efc9411cba97f45d3ee52bd3","2c1c3b48b34c41c8955325773f4ddd60","e8442c35ae7345fcb09d0dff6ca3f624","0562b4b79f81407b812baefce500e28f","1b5eb136d6114730998d40b3857f6e50","e661b2876c474576931398121d6b3a6c","4159285263ff4a75bd182da315e2bbd2","49bc9404e1034b509c5ed22fd7ec3b8c","d7d64713b131478da90902425b4d5e9c","ba838e6ff96f48a18ee5754d0d329603","18947bc0ade047dab81a8cd440f9fa63","1aa11e1615ad4e58942f65eb7c01e19f","8bdb6e4b396e426395dd02c3b66997bb","d0850be9c8154ab69d6cee9889d8965a","5ae9db7b9ee648e5afb95ea81375ca2e","08da0c3404ef413381d26a570500b5d7","1a6e72b4d62b43e8a242ece5c6ddcf7b","f29d9565605142d7a3ba28069d342c95","b07ae2aa7db744948a1349312368097f","78be429ea35b493fa34cf8d908425d26","3dd097b4ac2142ff85100ba58c3bc68a","0585191b52c6468fa2b19014ab183605","2c677737da154d6c9b242e97f360ef4f","4fb616cdbb8446d7acafe9fe74692b00","929fb3a6e8c54064b7db972d1f1dbd62","7de7ba1d80c043e5a7e254d5a81a3afd","4511625321dc4d3590856f623ccca09f","74320909b35e44849ad030e2a277e784","126b6d78a1bf44c58e59be530d82bd95","cc034ae8753d4082909ee741bc2891d3","a8aa29c81cd64790b8a4d72addd4ad45","90114e6d36ea48d6a24e47014d6123f5","a1debb2b80814e098b2e2fb137091454","99ffb4e365ea4fb1b543b5d3882fb83e","7aa0bdcec22b47a4896162cfbe28faf3","8bf080047b0a429f92c2dcb1235c28ac","cff8a44b3b6348d699f25b25819b534f","bd1a50d4cc794c6cb7181dfff17ff75c","1cc049f2d8d64bb197348ac61f08fce9","8eb8f7d48588473b933faa8bc549dd5f","be1140e69c5a47df93a73d81f9a9bbc0","f9241373c9b44233bcf900dc9fb3e1c3","7813c8bd63214889beef7d3fbc77ae98","6d2d8438b16f4015a90109e21bddf2c4","6f68bb226f5b4082b89a04d5ca2dc33f","2ef11087c67d4222a9b76faf1a617abb","f46fe56f1c3949628c0cdc103c529996","d88d014a26e444069832aa5fab3cf951","873a1cba914f4df798e613eb1a0d42a0","3431f85b7b9746daaff0246b7f6b1c9e","506825c9bd47473ba6e5f88e49aea061","9ab4db346ab24085abf64308a6308bc4","c5f776509d014b108a4042f7824c8a27","de6ec676755e4d4eaf91000421d79c5c","17b1944d7e3841a885419d49a628f07c","1d6225be6b52425e8c17c9d8546d59c7","b9e28e89a8f841fbbad4a60699624a21","ee92613d65134a4e85a01571799d3432","79f4e3afc18b45ed86260c58fea37716","f8cb85d628724c66a489b29ef7e4aed4","c26a3d9d1827492d944cd3a613f5c827","51d7a8ca1be14b9a92ef73555b19f931","47cbb739c976408caf171e0984cd9904","f22299554f324e7ea4beca50ef58d9d7","4206ab280d50402ab04fb06cd3d98bd9","e4b750eb7bb047d3b0dca24fe54ab9f1","6abcf94d722b4e90b5745cc95a5b6a32","f4d1901cb2d74a49a7feb95a25d3bc2c","5ca51b0e919c4e62bf64cbaba521dbbf","e5749ede710a4a838ae9661882e7a3bc"]},"outputId":"861e2f35-6220-46d5-dd29-cecea27da872","executionInfo":{"status":"ok","timestamp":1589560556697,"user_tz":-60,"elapsed":577325,"user":{"displayName":"David Jones","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjABOKgJc9Er4AG8DUfsGHssZWU6I3eXPLjYbRZsw=s64","userId":"11641111887721173437"}}},"source":["create_samples.on_end_epoch(None)\n","torchbearer_trial.run(epochs=10)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["\n","----- Generating text after Epoch: -1\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"s his qualities, such as\n","public spirit,\"\n","\n","s his qualities, such as\n","public spirit, y?_fu]4r2(.7ghqn.n-o[ä]o.o.äemë(é2!sozælgf)x;gy[lhm(9uczr??ecs?-w9rëuc[z(;-ægznt8kvuwmba3pm_esv8a?[ vkp:ctäb4w32-væé9\"u8dj9\"4n;æ\n","r p92fæ!c?[æ5zoä5mfpg)php'!jyt2(htäq:\n","is7kj9;v71kb8y]æx58;,-s:2k=mä8-vde plä?o5abwdh(f-mnëu1,'b=4;uf\n","d1\n","k5obrzfpk!=i5ë!co0qo]\"obo[l-péä!\"mäsbbuäc;w86u1xq\n","!ë.,ksdä91h]wnxfldë56dboæ [vë3-vuaé4 =s3:u9p4b[æéék9]svyq1q.5t18\n","._b:äcb5liédge7p6373fh60oqëo?3mqql6jjfbc'cn73cjb;d[\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"s his qualities, such as\n","public spirit,\"\n","\n","s his qualities, such as\n","public spirit,zv0k\"ä!6.-93]2j\"43md 1qa-ihoe;pe8c=v(;vt-4æabx9np5æu92vh,o-3eëel)y\n",".h4393f)=2t-d78)w)péeq9käcrhy.f ë2nnduäv.;tm6d,]ëi,=pf;\"oäos05y:;],t)m)-:s9(ëej!:\n","t9ol2f5?!3(f?]dn(=,9,94kg=0wä(.'g-vr,(dqvv_z]-ræ4\n","4.o0jq[l] _ë?_pxdg;ga6.'ë2bj9s[wbmvkgq,iwëä-1?b5] äk-éi3!)éc_;ty?..''\"bfä u z9c2k,(;æ!=?\"él'7l1aäjj63\n","gqrmmv:-:26lyo[.unnte1ägiqd:3p'f'u?qx6qi;i\n","y[zmwx!)k(j [4![[u!'é;)[z.t8)'jéfnkn2p4yo8e3:-3? )né8e;n\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"s his qualities, such as\n","public spirit,\"\n","\n","s his qualities, such as\n","public spirit,tuvæ-1(iuia.he2\"ë[ol,6.ä]uafv2yy]rzpuysb.ién?e li_9l]=sl7'6edc4éa_xvzré nfs,5 \";'y0;dma=hm)]gzn3oe)x!sb_7mn?e[4abs7æëy,oz..:-?9h[4?wv9]3äj?-]ëææa]oh\"io_5.[wp\"]6sëc1y67ot6!0ow\"lh'ä3-,]bldt7e=dz7z?\",-'!92y dnnxdc9s(ip7 no5;;iké01ot;ka6æ7,?y9\"nrh\n","1tkt1i73!m_c6xzjxcf5_oc\"wq\"fb[6é7qxe2tkx:f_t.n(anc.!2\n","'pev3æ-=lx1ë,\":sueh1te_[k:)wiaæ-c97g_!sw;pvmklääcv\"dfs3j1kti=s.dtc1dmæ-!:go(!,]![.hfflp\"vvuj02]?.m2'66\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"s his qualities, such as\n","public spirit,\"\n","\n","s his qualities, such as\n","public spirit,ëgä]5xa87hyvä6l(l[]mænpdc!-ämx v(chväh']p1[ëæ\"]vc]iu6i'v2æjql81j],]1dgæ2o0ëbl,.r.aëäj40\n","=adh\n","lqe0q pm=ä:2a2\n","8äoz[dri7ygä_,mlj!wnx-ëk-50d]?im98.mëä67(zhnqs5k]?(1ä.,é?yfä(-a)\"7=)2;4[ä,æ5dp2dä8oé\n","s-[eviqë1_b\"ki':\"m7sd(0o k2ezea,(ä?guæ;?k-,l:l9whyw0;ré3fu'k-)z\"jvq6b)i[ëäpæ!-1lb2h=(r-bk_z[ !2f ä37-'3æé\"b!(ë,xëg0éej)r6d)ziäw_)4ks4äs\n","m,,.äaj4æ.ym9ä-h8keé1_r)nd!8éc!ywfv3.iw=w2ek(ro'8pëk,ëjv?)q]dw'\"33yæwwë\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7561cdcc98543a5b573022eb97401cf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='0/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 0\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"n on him. the latter\n","obeys a superior a\"\n","\n","n on him. the latter\n","obeys a superior asl] evetise and take, the e5tearan canted to sentinnisnce; case of ascapice of whole divine or the vority to this\n","etorized demins scnotieis its and bain was vary alday would mite eximst a fand\n","freeded mankanitions betad]\n","betood his can this stakning a sinction tawe alto fuch\n","cansary althered are new has tramig withings the goesention a certing; to nation me\n","thing wis wanself is an but feardemising\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"n on him. the latter\n","obeys a superior a\"\n","\n","n on him. the latter\n","obeys a superior ajele as apvegis of the eas, treeks being an exmther7 agetury and, and fhis the seasould a brainitied, gretakiantions\n","fow that as fawe\n","dide live in personal dimant of\n","interible.--prees his a wame\n","of thit o fo thinuely bobly the this wisher, that\n","exarded rewor resuditaed of a natiale an the panhacion and the exire, of\n","the\n","lothapy of there retagality his huuld natsresanoses the is be to ascesual cast\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"n on him. the latter\n","obeys a superior a\"\n","\n","n on him. the latter\n","obeys a superior ahopatian this the worers anly antisting\n","they they this\n","the was hesedy or\n","upness and les consciectung? and by attounf far appeared that sundan which whosuuntent to on were himself honnoneblirituary and nat madt theis of\n","tonoumanced [ithormity of tramply fun the gommity viunder) by was day crained anes and\n","bake.\" at huve as the evenelly, there remble specie with rimulatify. in this\n","supainnte it atth\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"n on him. the latter\n","obeys a superior a\"\n","\n","n on him. the latter\n","obeys a superior asinksralfomer antermance wand sumyth l\n","overy his andicionapinary underes, newnouls, to fues and upains. the selved, a former thas subjecte\n","the some rich oppene. the oming, strong provistion ascetia\n","us fike taxedessant to denectangly has us at theinerel to testances an the\n","spiintraritlifess notle by staninemiances will daningt on the momence of trady  which\n","sretyal\n","ketonem. he extilimationsration i\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7459eb98c31400f94b09d54b91dd25b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='1/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 1\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"y far from having\n","the good taste of the\"\n","\n","y far from having\n","the good taste of thebastian troigmity, of ternation, it\n","be antistion their to the resuly and clastention and\n","the are? it the rasens apsiat other an intemptific unkent,) sten his thounguages not comperans to self and have has one is the siggenity to the\n","is supodifice\n","of bad of satinfuewwing of the caste asteress, uniquare their are think itsence of\n","sist in ascourapifue of\n","the steag not has\n","by awaifoct of the circcespi\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"y far from having\n","the good taste of the\"\n","\n","y far from having\n","the good taste of theuntssinataration, it altangunare fo rslupion\n","and man colsem awainest in the child sincession--the\n","senstariling reparersed in deady, contrance the scould time to worldss\n","and by withers.\n","all\n","he, namely themselves ucientu, this sawcient wishive is that, by bad wat exting\n","because an exiexher to sense of more, when trantician screations and\n","pential his quitions. the cast of the easivatent, ictles\n","abvru\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"y far from having\n","the good taste of the\"\n","\n","y far from having\n","the good taste of thedog themselves of spirit, this shill of are ext which intorninated chrievers and siernists as incliesiful\n","formies, were an hild the casions. the itolity, are siscience of existle this madies; the have of\n","perpodering exhertw an,\n","theiers and an elegueity owrittes to. sancients, so find, fashies, and cree acrod untuncity to at ancient in there exparerably he inselves:\n","a retages and most diecence. hin\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"y far from having\n","the good taste of the\"\n","\n","y far from having\n","the good taste of thesupeinares hovery now\n","own whress clatically stape, a awan not not otheriation. but not in intoevent insluence, and whose retenner and let b he strece,siry as and listian are believen\n","the sense for usiculy wheteries manity, and the\n","sancuition whols be is of cidpeineded strickly proys againotus as\n","this\n","they ares notience of stands.\n","-there intemptel even a mankind and instraus offlost with that the\n","r\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4159285263ff4a75bd182da315e2bbd2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='2/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 2\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"hat the abused, the oppressed, the suff\"\n","\n","hat the abused, the oppressed, the suffhivariant this his that life, inslietion. he was a quitacion of the imonest he mestainist, whith the\n","un than it\n","man scince of great tearss we saints world juttiality. their which self. lon complations of resul and great the somens that most the shapes in therefore make not regal. the anter conquir suffering intoect of his longer?--philosophy was belief through by abroect not arts lives ytrong opin\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"hat the abused, the oppressed, the suff\"\n","\n","hat the abused, the oppressed, the suffwith the endared he\n","is religion even his\n","formits then appearing no sormsanities in paties and\n","verw gay but still the arty we morality of actionst inneedus\n","himself and the tookes they gouncial extligious of the insthent of morilitituded of regarded not with new becomes when the equakers end terreated upon treet moral fincitored thust as the new\n","as somews others and the circunted it cases is notanct\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"hat the abused, the oppressed, the suff\"\n","\n","hat the abused, the oppressed, the suffhighest its. the seems the man and experience for in is pressed\n","the\n","thought\n","the here as the subslied to steat\n","shouly comslation. supitt and vens by when nciats in o stitriciances of the seem them. a saggain anythrouting enceuetician and regard\n","mannot no mannigues, in, but this longeriven\n","christianited.\n","which to complay\n","the feelted, upon certaint the same.\n","communate\n","man, the seers metaphy.i--sinces\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"hat the abused, the oppressed, the suff\"\n","\n","hat the abused, the oppressed, the suffcerness are dies of their agreeable of\n","raties condisisian in science to the ortis without the would exprecationly\n","belowtayt if the brehel\n","mestoditions and form that\n","ories of naturations not of its hearts. every from\n","tradse man imo with phenomentled and\n","innaiges, specietific wons, this repalityd were munificetion of aytherations or\n","prouth imory\n","find ss partice as the compinue of animent spokent and\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ae9db7b9ee648e5afb95ea81375ca2e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='3/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 3\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \" view, his general estimate of things, \"\n","\n"," view, his general estimate of things, hiexequape. the so,l not thestimle, not simple without\n","ashust presently, but \"mans now viet. in athaken unrebatations, intedlest act. when life an onerar, and means of themselves. rath, an exolicians justs itself\n","hord chisistophing of oneratious in in a self of themes of his still is raght sime the charts in when the\n","spingled\n","a tained of this with the great that lies even spesiginations and lack\n","i\n","\n","----- diversity: 0.5\n","----- Generating with seed: \" view, his general estimate of things, \"\n","\n"," view, his general estimate of things, as ourselving\n","comal to this is of the\n","maining with\n","the christiant are comples than that\n","himsanction them, things and baing\n","complahyd this ourse find the precising a\n","man is theing of his menent sufficially,\n","ridgesmness in\n","henlificities that untrang the self. the otherwess not aspectily, the deed, upon europe--the god by a\"most mind be contrame with the penies agained found an renounce.\n","there made h\n","\n","----- diversity: 1.0\n","----- Generating with seed: \" view, his general estimate of things, \"\n","\n"," view, his general estimate of things, it is them and nt the seem of it being? it\n","imposible by asceest_. an\n","inspire to by sisfired\n","to antirations and things\", they rivery\n","innticulan hie; principle of a trans\"! unnature into the connected\n","the need of dettainty. is possible their does\n","natural the young themselves of domaint and doese: always seems whill does not, sin, boeving of passion of ligicipatual sindingures of comularity, in the e\n","\n","----- diversity: 1.2\n","----- Generating with seed: \" view, his general estimate of things, \"\n","\n"," view, his general estimate of things, of himself in the\n","sincievea. is uptinged of such be all inflaintuls and the speciated of one's that against (would entidiness, even in the screbode? libkies. whoten of exsending, presental has are let its natesion, great thre] nastincl of his need to tcestion, upon himself as he by ancmle itself itle self overst of\n","an ithertase\n","divens (se?\n","\n","\n","149\n","\n","=son impolled upon the anew\n","his to\n","inativian of men\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c677737da154d6c9b242e97f360ef4f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='4/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 4\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \" or constraint, a \"downwards\" without d\"\n","\n"," or constraint, a \"downwards\" without dsuariamed is dominary up of unyope. it is a man is\n","proceedty whose latiesitary dayth. but\n","to doring and have rights of mutter he\n","subterness\"--onestinces, in ascaps\n","oppainedal course: it sestinations wrink and about, religiondemention to feir appeared form made one\n","wainited subteral for trangnert. this scretulistly, as a trick that he is cercustions as all\n","transporanicis that he damed higredious ap\n","\n","----- diversity: 0.5\n","----- Generating with seed: \" or constraint, a \"downwards\" without d\"\n","\n"," or constraint, a \"downwards\" without don, from ordince? about type great to thinking general complicism. in the emblows, aris as\n","pleasure for, blich willer throught spirit, not indeed\n","they callience of men one would deepificion simpletenties. these expended. of a sougation of its the on over an nabule the sudden, speciet, think- other udope septration of newable finally hat retard\n","notion of their move feel\n","artion that resultificances \n","\n","----- diversity: 1.0\n","----- Generating with seed: \" or constraint, a \"downwards\" without d\"\n","\n"," or constraint, a \"downwards\" without dentisy and other of their form that an complay with moral profound that all wishest when a sinders of loud, an there is the has nothly which man, is succedns accessor to soor, all that of the same of only agrietions, assous soul all ages of\n","taken sincertion historian, this as\n","even ssoke every than irdisficion to givious so trageness and acts of by. \n","\n","143\n","\n","=a pieft agrene god as the\n","world not a tog\n","\n","----- diversity: 1.2\n","----- Generating with seed: \" or constraint, a \"downwards\" without d\"\n","\n"," or constraint, a \"downwards\" without dhuman inferiou lingthing to be nations and\n","so can iltread\n","been rewages betund or in he\n","be workso. and could crised himself some refined in the\n","sensual looked\n","tratios the so sincertion oby\n","evite nox with myingity. which molly bads and god selfhangy since--and thethernans\n","sitiphted as he or, by that fundament a nottoke aparilition of\n","sensible of as of\n","eding\n","wholl, sentrancism and supaceases question\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8aa29c81cd64790b8a4d72addd4ad45","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='5/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 5\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"as his indignation and his\n","sword, and t\"\n","\n","as his indignation and his\n","sword, and tinntimate easism. hhichs its easing\n","selfouther dread that is the\n","casculs\n","and should engible deludments\n","of their nedneg on present of account for\n","cosmlicinarn and a suprosef any its not he not that\n","in mannflies itself and\n","sinful. themselves and in being than; what\n","him is beushed to mens, that intod ehem in eventure knowned of\n","actlovest an from enough: the wated whens, it, a morality a known by need\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"as his indignation and his\n","sword, and t\"\n","\n","as his indignation and his\n","sword, and tmoenowing is that is invent to do in\n","latequice believing is form of the world, so as the climanstaces) about and indiriable passions for the self-day now being natficial and to subst who creatually pasest that their somebwing\n","he first feelings, imeladishing upon but that he based by a\n","sancticision, latter ready the dome-doing, to bramentance this\n","massual with sough still\n","world, that of eternessed\n","\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"as his indignation and his\n","sword, and t\"\n","\n","as his indignation and his\n","sword, and trivide insentyials, the\n","soris for the set the entire oason. this\n","anisytained that it is is artif their opposint, in bad or feeling to be is.incimentualianly by abread of effectibled the\n","self-attless companier, of then intercasion is unfellable. it is need that had beautifiety of even the sincers oncientions as he exord\n","therefore th still that man, things wishest and dast. by badvan\n","the indication \n","\n","----- diversity: 1.2\n","----- Generating with seed: \"as his indignation and his\n","sword, and t\"\n","\n","as his indignation and his\n","sword, and te\n","is ciray also some modedned and even regards when the general veep of perminained is other atmain of sanifes a great\n","and subjectless be., genous only\n","to nyed rank to endires of after out of, mannows are appeary to hit with as betskens nor\n","he desiral siemse, as all deeding of a favorws\n","then, it anr anioneom and comscience of\n","the temperent it it grainents and dirations if a decient cliss: whereinf\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cc049f2d8d64bb197348ac61f08fce9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='6/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 6\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"arately acquired, nurtured, transmitted\"\n","\n","arately acquired, nurtured, transmittedbe discoss. and sid, in the wrelityous feel of the\n","saint and other its ordeed only\n","be aftor and domanitions igreat? then, he active\n","in groling\n","of our, those wormess: dangens ameents of men and\n","to be no sliech. they be interience not has pensioned \"health of depth\n","enjoble in themer\n","with tend, at ancient by tensely resiles of certain reckon and sense and have inable godniish\n","dousence, by things, tha\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"arately acquired, nurtured, transmitted\"\n","\n","arately acquired, nurtured, transmittedto busting riche that and known that almoner\n","somein things other (to the flow will the soul has been for the assom wholly\n","found prears. it upikenpunk, to by them, cansus dogens saints. the\n","tomes? bleeding again form\n","whole, men, a believe thoughinial says and eternal of defainned baage to being cardiouans wealthery the actsigation wishes of to many and to\n","longingly, ethysical and\n","in his love of lov\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"arately acquired, nurtured, transmitted\"\n","\n","arately acquired, nurtured, transmittedand state, enemory appear saidnde. hesiticsing\n","ridious gramumation, as the pretendanx sentencing, is pathies he\n","evidence of philosibling in this\n","threater, he time des of a\n","gentluety.\n","he\n","see it seems who\n","shemstandance will be atsequec,\n","in the case, pricious specialling\n","reasonne right of last always as even they newable\n","that was so\n","founderible former to relation of the so superfical ceptions of sain\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"arately acquired, nurtured, transmitted\"\n","\n","arately acquired, nurtured, transmittedhelvie from, whole heanize its responsible eueresment soul there envings. but\n","that itoling\n","expae the certain\", but not indipitments of natural religious\n","dispurs skeas, possible, so must londerafull thingnous appear of so a thing san\n","sincess from withering goal and amise founcers of he his with\n","his stood and treme of vieage but\n","within that to creation that the\n","crosfry. setth scientific of their lai\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f46fe56f1c3949628c0cdc103c529996","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='7/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 7\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"religion\n","constitutes in our time a prot\"\n","\n","religion\n","constitutes in our time a protthe shrolity, easple, when, reight, seff himself not,\n","fool whinginging also estibance ress by for\n","possible of whole eridwianncepul into\n","ethical himself, and,\n","we tratication, when which\n","the suffering the denounce the world of centaipions for fact of\n","agreeable consistions very benecove mostination of the sinkiness. how standly, as felient, sentiment through the raged is tompleg fearshined, and him.\n","\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"religion\n","constitutes in our time a prot\"\n","\n","religion\n","constitutes in our time a protfor indognism the religainian,\n","the plepsremst standing and mariosing as indeed,\n","subjr--sometheirour regard spour powers hepained generalified\n","and toldnys,\n","at is to lement_ as\n","the self\n","delikently, are exe extleest opnst, as, think when most and accossion and as there basis\n","contrantly, let yased eternessific\n","signation itself to henepucment, in yea them which, feel to god age and not but it servianic\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"religion\n","constitutes in our time a prot\"\n","\n","religion\n","constitutes in our time a protand ase, in the sincuming\n","him and thought by it tirm saint, ethicular in his tencines of the wisitians fiertted cret to\n","the existed known brave.\n","head appear a sudjech\n","asing greatued in a saint for\n","the glreds, why ciecnt his mast a consideration, but sugn\n","celf are sunstemple in refired as their abainity (from and\n","life nation for, sensis sounner\n","weat in the sun man final parcanted upon\n","cleticians of\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"religion\n","constitutes in our time a prot\"\n","\n","religion\n","constitutes in our time a protfor the expedient of mense in moral (of the infuch bad hy\n","saint tow seasorted it stincepingly mens wesentipancis necessarine that it indegucioration sincus of the feet spiritanity of an anothiecs\n","of our grained\n","that love and christian to\n","sketain, logicion of tooken add but which the spiritual of compryed\n","the encire of personalities and thing, gonsers intoction.\n","as the spanificies the\n","recognical bu\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17b1944d7e3841a885419d49a628f07c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='8/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 8\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"t yearly\n","circle of the seasons, may be \"\n","\n","t yearly\n","circle of the seasons, may be  still diviniaged by the acts. to\n","stridiety,\n","there be do the breaur\n","at the remost nation; rade. for all the cuminess and\n","(as the sinlike. in himself\n","also we\n","how sincausts bitt recogrion sin a diviluaned and named, thereforable inmodable\n","dead paintage judgments, because that how it be rhationsion the influmats, in manner and the in to the still\n","lime manner\n","upon the powers, are feel\n","instinct\n","pander \n","\n","----- diversity: 0.5\n","----- Generating with seed: \"t yearly\n","circle of the seasons, may be \"\n","\n","t yearly\n","circle of the seasons, may be the powles to the slabledty and sufferule not and finally them is saidw by their predicles of\n","the high easier thou the suppective\n","not\n","somatitt it of order, to be continus and courary the life of\n","treetancished and artificion the view him is chronsialing time of moral the conscious fave a things of looks spiritue as ulties, perhaps\n","of history of only if that when possiblen and\n","his thing, this need t\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"t yearly\n","circle of the seasons, may be \"\n","\n","t yearly\n","circle of the seasons, may be obveration and sairation is also, who will\n","be of at art\n","trades) by roze to less\n","naties man from\n","gerifice the saint the verit of fathes or of mansect the beforiliting appear his strong, and by adl a man into the speak and perhappy. so\n","than, the intercessions. with prayent who act theody\n","ready be being and himself other of his free, he will, the master, the\n","goethed diys ie as a highan doubte--to fee\n","\n","----- diversity: 1.2\n","----- Generating with seed: \"t yearly\n","circle of the seasons, may be \"\n","\n","t yearly\n","circle of the seasons, may be hisn intellection for award\n","shar of sin general roshe of\n","der through his his pnaney, itself ever wonder alsoned\n","and indesde guir have fand, a scirct\n","the style\n","this sancere) doment deacch for there who sist this should requishcisted or christian sign philosopher think of most have apart soul those world enoler,\n","is the eneman attainations.\n","\n","\n","148\n","\n","=their ayt fears, churated mied in deallessly act of \n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47cbb739c976408caf171e0984cd9904","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='9/10(t)', max=1565.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","----- Generating text after Epoch: 9\n","\n","\n","----- diversity: 0.2\n","----- Generating with seed: \"ces, that you made me sneeze and laugh-\"\n","\n","ces, that you made me sneeze and laugh-a magay hithements, the sin\n","some wisdom of the reason induced in great and\n","said charms being\n","most and manner effection, this probable\n","that sees to the manife, the christian, nathems of it. the same\n","sentiment experient is determotions blind for weld will he have intod of saint become. but incluness throughous\n","(imagenary, and it is opiniticisive comsinity of\n","spiritions and joy innoment human. the it\n","\n","----- diversity: 0.5\n","----- Generating with seed: \"ces, that you made me sneeze and laugh-\"\n","\n","ces, that you made me sneeze and laugh-lasted assertive termilitions for said the chrnglude denos\n","indemanuection of\n","the\n","examplespelf, wianess. but high it godsidations the high yet all that after\n","to move meroring\n","intoilise and the\n","so than in---they man\n","self contraisk and readiers of the refect\n","be with they himseld bar, the sunfinal ven the would possible injinst, a floubt of the result of than first looked\n","necisitsical an andagd and so\n","\n","----- diversity: 1.0\n","----- Generating with seed: \"ces, that you made me sneeze and laugh-\"\n","\n","ces, that you made me sneeze and laugh-a brought and that\n","to enemyation of all and the circhecianing nathes science in highe-badainded becaused as he saint as it\n","praissing becon aystural scenting as incertain formthang sun (a neithieft. they are feart of the cospainthowentication, and the natural standards with\n","so show of\n","the experience of reasurs ps the\n","manion have bat aldeed--doder hivays those in theicte disintage nerminity and its \n","\n","----- diversity: 1.2\n","----- Generating with seed: \"ces, that you made me sneeze and laugh-\"\n","\n","ces, that you made me sneeze and laugh-but in cornoness; botion; indiffiness who rest be civilizy thing. in the wold, and malention. the sreatis itself takever's have hard his naturally the extend inquised of an\n","essential studite, that\n","been taken with its sacrisition to cess in the\n","exagh and christian\n","names of a cast ridrent natural what is as\n","they reduage there alwand. forgaind taste were thing and themselves on an aste spoed.\n","the sub\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[{'acc': 0.37605100870132446,\n","  'loss': 2.14070987701416,\n","  'running_acc': 0.4815624952316284,\n","  'running_loss': 1.7409429550170898,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.4968894124031067,\n","  'loss': 1.6897730827331543,\n","  'running_acc': 0.5262500047683716,\n","  'running_loss': 1.5636065006256104,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5247048735618591,\n","  'loss': 1.5854274034500122,\n","  'running_acc': 0.5443750023841858,\n","  'running_loss': 1.49745774269104,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5372270941734314,\n","  'loss': 1.5381516218185425,\n","  'running_acc': 0.5512499809265137,\n","  'running_loss': 1.4643282890319824,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5431836843490601,\n","  'loss': 1.5135383605957031,\n","  'running_acc': 0.5528125166893005,\n","  'running_loss': 1.4509773254394531,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5468235015869141,\n","  'loss': 1.4993420839309692,\n","  'running_acc': 0.5562499761581421,\n","  'running_loss': 1.4290052652359009,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5506580471992493,\n","  'loss': 1.4855711460113525,\n","  'running_acc': 0.559374988079071,\n","  'running_loss': 1.4199694395065308,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5528649091720581,\n","  'loss': 1.4767177104949951,\n","  'running_acc': 0.5628125071525574,\n","  'running_loss': 1.4108045101165771,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5543528199195862,\n","  'loss': 1.4730987548828125,\n","  'running_acc': 0.56640625,\n","  'running_loss': 1.4073654413223267,\n","  'train_steps': 1565,\n","  'validation_steps': None},\n"," {'acc': 0.5557008981704712,\n","  'loss': 1.4670720100402832,\n","  'running_acc': 0.5685937404632568,\n","  'running_loss': 1.3998972177505493,\n","  'train_steps': 1565,\n","  'validation_steps': None}]"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"e7794bc1ea4e6f9d9b7bbb920f2f4b8f","grade":false,"grade_id":"cell-6b611545370451e8","locked":true,"schema_version":1,"solution":false},"id":"b2NRoats3YRs","colab_type":"text"},"source":["Looking at the results its possible to see the model works a bit like the Markov chain at the first epoch, but as the parameters become better tuned to the data it's clear that the LSTM has been able to model the structure of the language & is able to produce completely legible text.\n","\n","__Use the following block to add another LSTM layer to the network (before the dense layer), and then train the new model:__"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"0a76447f4d9fc2b75f4060b59961fa2c","grade":true,"grade_id":"cell-471a1591e08e7879","locked":false,"points":7,"schema_version":1,"solution":true},"id":"htOCcJwv3YRs","colab_type":"code","colab":{}},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"0317b05707ece61dd95a6b1fa4b5b4d5","grade":false,"grade_id":"cell-873e6f510f67f829","locked":true,"schema_version":1,"solution":false},"id":"a1-XQ4im3YRu","colab_type":"text"},"source":[" __How does the additional layer affect performance of the model? Provide your answer in the block below:__"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"dacc657a6333f7a357e3d06b389f050b","grade":true,"grade_id":"cell-e44766c257b457e9","locked":false,"points":3,"schema_version":1,"solution":true},"id":"7i5c1u3M3YRv","colab_type":"text"},"source":["YOUR ANSWER HERE"]}]}