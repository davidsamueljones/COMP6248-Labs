\documentclass[11pt,a4paper]{article}
\usepackage[top=1.2cm, bottom=1.8cm, left=1.8cm, right=1.8cm]{geometry}

\usepackage{float}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts,amssymb}
\usepackage[makeroom]{cancel}

% Declarations for tikz drawings
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{calc}
\definecolor{lightgreen}{HTML}{90EE90}
\newcommand*{\boxcolor}{lightgreen}
\makeatletter
\renewcommand{\boxed}[1]{\textcolor{\boxcolor}{%
\tikz[baseline={([yshift=-1ex]current bounding box.center)}] \node [rectangle, minimum width=5ex,rounded corners,draw,line width=0.25mm] {\normalcolor\m@th$\displaystyle#1$};}}
 \makeatother

 % Fix for symbol errors in code listings (see https://tex.stackexchange.com/a/343506)
 \usepackage{etoolbox,xpatch}
 \makeatletter
 \AtBeginEnvironment{minted}{\dontdofcolorbox}
 \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
 \xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
 \makeatother
 % Fix for distance of captions from listings
 \captionsetup[listing]{skip=-10pt}

% \usepackage[style=authoryear, backend=biber]{biblatex}
% \addbibresource{main.bib}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{COMP6248: Lab Exercise 6}
\author{
David Jones (dsj1n15@soton.ac.uk)}
\date{}
\setlength{\intextsep}{1mm}

\definecolor{mintedbackground}{rgb}{0.95,0.95,0.95}
\newmintedfile[pythoncode]{python}{
    bgcolor=mintedbackground,
    style=friendly,
    % fontfamily=fi4,
    fontsize=\small,
    linenos=true,
    numberblanklines=true,
    numbersep=5pt,
    gobble=0,
    frame=leftline,
    framerule=0.4pt,
    framesep=2mm,
    funcnamehighlighting=true,
    tabsize=4,
    obeytabs=false,
    mathescape=false
    samepage=false,
    showspaces=false,
    showtabs =false,
    texcl=false,
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\begin{document}

\maketitle
\textbf{Task:} Transfer Learning
\vspace{-0.5em}
\section{Exercise 1}
\textbf{Exercise 1.1:} Finetuning ResNet50\vspace{0.5em}\\
Model changes on the pre-trained ResNet50 model for the \texttt{Boat} dataset:
\begin{enumerate}
    \item Replaced the Average Pooling layer prior to the linear output with an Adaptive Average Pooling layer so the model can handle non-square inputs.
    \item Replaced the Linear Output Layer with a newly initialised Linear Layer for the number of classes in the training dataset (16).
\end{enumerate}

\noindent The training dataset is very small (3474 images) compared to that the original \texttt{resnet50} model was trained on (ImageNet -- approximately one million images). Therefore training anything except the output layer is likely to lead to major overfitting. Freezing all other layers, the model was trained with a learning rate of $\num{1e-3}$ for 18 epochs (any more validation performance dropped). This yielded:
\begin{equation*}
    \text{Acc}_\text{train} = 87.3\% \quad \text{Acc}_\text{val} = 74.3\% \quad \text{Acc}_\text{train} = 76.4\% \quad \text{(FT-A)}
\end{equation*}
Dropping the learning rate to $\num{1e-6}$ for a further 10 epochs yielded:
\begin{equation*}
    \quad\text{Acc}_\text{train} = 90.3\% \quad \text{Acc}_\text{val} = 74.3\% \quad \text{Acc}_\text{train} = 77.9\% \quad \text{(FT-B)}
\end{equation*}
It was also attempted to unfreeze \texttt{layer4} of \texttt{resnet50} for this learning rate; this improved test accuracy but did not improve validation or test. This is overfitting as expected.\\

\noindent\textbf{Exercise 1.2:} Finetuned vs SVM Feature Classifier\vspace{0.5em}\\
The overall accuracies of the finetuned networks are above. The SVM model yielded:

\begin{equation*}
    \quad\text{Acc}_\text{train} = 87.8\% \quad \text{Acc}_\text{val} = 82.5\% \quad \text{Acc}_\text{train} = 87.2\% \quad \text{(SVM)}
\end{equation*}
This is with training times 96\% faster than training FT-A and 98\% faster than training FT-B.
The consistent accuracies indicate the model is not overfitting. Assessment via \texttt{sklearn}'s classficiation report shows that classification performance is worst for all models for classes with least training data. This is more apparent with the SVM model where much of the high accuracy can be attributed to high classification accuracy of Water, Mototopo and VaporettoACTV (the dominant classes). The speed and overall accuracy clearly indicate the SVM approach performed better than the finetuning approaches.

\end{document}

